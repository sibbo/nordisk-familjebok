{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking articles between editions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_searcher import NeuralSearcher\n",
    "from qdrant_client import QdrantClient\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "e1 = 'e1'\n",
    "e2 = 'e2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Qdrant client\n",
    "client = QdrantClient(host=\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entries fetched.\n"
     ]
    }
   ],
   "source": [
    "# Fetching entries\n",
    "vectors = []\n",
    "batch_size = 50 # This value has to be chosen carefully (Experience from testing)\n",
    "offset = None\n",
    "while(True):\n",
    "    response = client.scroll(\n",
    "        collection_name=e1, \n",
    "        with_payload=True, \n",
    "        with_vectors=True, \n",
    "        limit=batch_size,\n",
    "        offset=offset\n",
    "        )\n",
    "    records = response[0]\n",
    "    offset = response[1]\n",
    "    vectors += records\n",
    "    if len(records) < batch_size:\n",
    "        print(\"All entries fetched.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81369/81369 [20:36<00:00, 65.79it/s]\n"
     ]
    }
   ],
   "source": [
    "neural_searcher_e2 = NeuralSearcher(collection_name=e2)\n",
    "\n",
    "# Create links from entry ids of e1 to e2\n",
    "links_e1_to_e2 = {}\n",
    "for entry in tqdm(vectors):\n",
    "    entry_id = entry.payload['entryid']\n",
    "    matches = neural_searcher_e2.search(entry.vector) # Can search with treshold instead\n",
    "    # Run matches through a NN perhaps\n",
    "    if matches:\n",
    "        links_e1_to_e2[entry_id] = matches[0]['entryid'] # Changing the search limit to 1 would make it a lot faster\n",
    "\n",
    "# Create links from entry ids of e2 to e1\n",
    "links_e2_to_e1 = {value: key for key, value in links_e1_to_e2.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make linked json files\n",
    "def write_linked_json(in_name: str, out_name: str, links_dict: dict[str, str]) -> None:\n",
    "    with open(in_name, 'r', encoding='utf-8') as infile:\n",
    "        json_items = json.loads(infile.read())\n",
    "    \n",
    "    data = []\n",
    "    for item in json_items:\n",
    "        item['second_edition_key'] = links_dict.get(item['entryid'], \"\")\n",
    "        data.append(item)\n",
    "        \n",
    "    with open(out_name, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing e1_linked.json\n",
      "Finished writing e2_linked.json\n"
     ]
    }
   ],
   "source": [
    "write_linked_json('e1.json', 'e1_linked.json', links_e1_to_e2)\n",
    "print(\"Finished writing e1_linked.json\")\n",
    "write_linked_json('e2.json', 'e2_linked.json', links_e2_to_e1)\n",
    "print(\"Finished writing e2_linked.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Go through e1\n",
    "#   for every article, search for c\n",
    "\n",
    "# for each article in e2, compare text to qdrant e1, get closest matches\n",
    "# For the closest match, calculate cosine similarity, compare headword, edit-distance, \n",
    "# other features, threshold function.\n",
    "# If match, change in e1 and e2, other edition key to match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
