{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the entry classifier\n",
    "Creating automatically annotated training data and training the model.\n",
    "\n",
    "Most of the functions used are located in `entry_classifier_utils.py`.\n",
    "\n",
    "This notebook was largely adapted from a lab in the course EDAN20 â€“ Language Technology at Lund University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')  # Assuming the parent directory\n",
    "\n",
    "import joblib\n",
    "import regex as re\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.scraping_and_segmenting_helpers import *\n",
    "from utils.paths import *\n",
    "from utils.entry_classifier_utils import *\n",
    "\n",
    "entry_classifier_models_folder = \"entry_classifier_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_file = 'training_data.json'\n",
    "\n",
    "classifier_remove_tags = [\n",
    "    [\"<b>\", \"\"],\n",
    "    [\"</b>\", \"\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating (automatically) annotated training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = edition2_volume_start_end.keys()\n",
    "\n",
    "labeled_data = []\n",
    "\n",
    "is_entry = False\n",
    "first_letter_list: list[str] = []\n",
    "for volume in tqdm(volumes):\n",
    "    first_letter_boundary = 0\n",
    "    volume_letters_index = -1\n",
    "    page_nbr = 0\n",
    "    with open(f\"{E2_TXT_FOLDER}/\" + f\"{volume}.txt\", \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            pagenbr_matches = re.search(r'page_number=(\\d+)', line)\n",
    "            if pagenbr_matches:\n",
    "                page_nbr = int(pagenbr_matches.group(1))\n",
    "                if page_nbr > first_letter_boundary:\n",
    "                    volume_letters_index += 1\n",
    "                    first_letter_list = edition2_volume_letters[volume][volume_letters_index][0]\n",
    "                    # try:\n",
    "                    first_letter_boundary = edition2_volume_letters[volume][volume_letters_index][1]\n",
    "                    # except:\n",
    "                    #     print(f\"volume = {volume}, volume_letters_index = {volume_letters_index}, page_nbr: {page_nbr}, \")\n",
    "                    #     break\n",
    "            else:\n",
    "                line = line.rstrip()[:MAX_ENTRY_LENGTH]\n",
    "                if line: # and (len(line) > 40) and (len(line) > 75 or line.find(\". Se \") == -1):\n",
    "                    item = {}\n",
    "                    # --- BOLD MATCHING --- create ground truth\n",
    "                    if line.startswith(tuple([f\"<b>{l}\" for l in first_letter_list])):\n",
    "                        line = clean_html_markup(line, classifier_remove_tags)\n",
    "                        item[\"class\"] = 1\n",
    "                        is_entry = True\n",
    "\n",
    "\n",
    "                    elif line and (not line.startswith(\"Fig. \")) and (not line.startswith(\"Ord, som saknas under K\")) and (not (line[0] in first_letter_list)) and line[0] in ALPHABET:\n",
    "                        item[\"class\"] = 0\n",
    "                        is_entry = True\n",
    "                    \n",
    "                    if is_entry:\n",
    "                        item[\"text\"] = line #this one should be last\n",
    "\n",
    "                        labeled_data.append(item)\n",
    "                        is_entry = False\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for item in labeled_data:\n",
    "    item_class = item['class']\n",
    "    text = item['text']\n",
    "    values = [item_class, text]\n",
    "    dataset.append(values)\n",
    "\n",
    "dataset[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building ${X}$ and ${y}$\n",
    "We can now enrich the dataset with a numerical representation of the sentence. We use the utility functions and we call this new version: `dataset_num`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num = []\n",
    "for datapoint in tqdm(dataset):\n",
    "    dataset_num += [list(datapoint) + [build_freq_dict(datapoint[1])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = [x[2] for x in dataset_num]\n",
    "y_cat = [x[0] for x in dataset_num]\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(X_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(v, f'{entry_classifier_models_folder}/dict_vectorizer_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=50, verbose=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "report = classification_report(y_test, y_test_pred, target_names=[\"Not Article\", \"Article\"])\n",
    "\n",
    "with open(f\"{entry_classifier_models_folder}entry_classifier_stats.txt\", \"a\", encoding='utf-8') as file:\n",
    "    file.write(\"Confusion matrix for test data: \\n\")\n",
    "    file.write(f\"{np.array2string(conf_matrix, separator=', ')}\\n\")\n",
    "    file.write(\"------------\\n\")\n",
    "    file.write(f\"{report}\\n\")\n",
    "    file.write(\"------------\\n\")\n",
    "    file.write(f\"Micro F1: {f1_score(y_test, y_test_pred, average='micro')}\\n\")\n",
    "    file.write(f\"Macro F1: {f1_score(y_test, y_test_pred, average='macro')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, f'{entry_classifier_models_folder}model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
